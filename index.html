<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
  <meta property="og:image" content="/images/profile_new.png">
  <link rel="stylesheet" href="styles.css">
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
  <title>Vardaan Pahuja</title>
</head>

<body>

  <nav class="site-nav">
    <div class="nav-inner">
      <a href="#about">About</a>
      <a href="#news">News</a>
      <a href="#research">Research</a>
      <a href="#publications">Publications</a>
      <a href="#service">Service</a>
      <a href="#awards">Awards</a>
    </div>
  </nav>

  <div class="page-wrap">

    <!-- About / Profile -->
    <section id="about" class="profile-section">
      <div class="profile-text">
        <h1 class="profile-name">Vardaan Pahuja</h1>
        <p>I am a Ph.D. student in CSE at The Ohio State University. I am fortunate to be advised by Prof. Yu Su. I graduated with M.Sc. (thesis track) in Computer Science from Université de Montréal (affiliated with MILA). Prior to this, I was working as Software Engineer in IBM India Research Lab., Bangalore. I graduated with Bachelor of Technology (Hons.) from IIT Kharagpur, India, and was awarded the prestigious Institute Silver Medal. I spent three wonderful summers as a research intern at Microsoft Research, Google Brain, and Bosch AI Research.</p>
        <div class="job-notice">
          I'm on the 2026 industry job market and seeking full-time Research Scientist opportunities.
        </div>
        <div class="profile-links">
          <a href="mailto:vardaanpahuja@gmail.com">Email</a>
          <a href="/reports/CV_VardaanPahuja.pdf">CV</a>
          <a href="https://twitter.com/vardaanpahuja" target="_blank" rel="noopener noreferrer">Twitter</a>
          <a href="https://www.linkedin.com/in/vardaanpahuja/" target="_blank" rel="noopener noreferrer">LinkedIn</a>
          <a href="https://scholar.google.com/citations?user=0O6NKfIAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Google Scholar</a>
        </div>
      </div>
      <div class="profile-photo">
        <img src="images/profile_new.png" alt="Vardaan Pahuja">
      </div>
    </section>

    <!-- News -->
    <section id="news">
      <h2 class="section-heading">News</h2>
      <ul class="news-list">
        <li>[Jan 2026] One paper accepted to ICLR 2026.</li>
        <li>[Oct 2025] Recognized as top reviewer at NeurIPS 2025.</li>
        <li>[Oct 2025] Presented <a href="https://arxiv.org/pdf/2502.11357" target="_blank" rel="noopener noreferrer">Explorer</a> at <a href="https://engineering.osu.edu/events/2025/10/graduate-engineering-research-symposium">OSU Graduate Engineering Research Symposium</a>.</li>
        <li>[June 2025] Serving as emergency Area Chair for ACL ARR May 2025.</li>
        <li>[May 2025] My internship work Explorer is accepted to ACL (Findings) 2025.</li>
        <li>[Feb 2025] The preprint for my internship project at Microsoft Research is now available on arXiv <a href="https://arxiv.org/pdf/2502.11357">[Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents]</a>.</li>
        <li>[July 2024] Our work <i>Reviving the Context: Camera Trap Species Classification as Link Prediction on Multimodal Knowledge Graphs</i> has been accepted to CIKM'24.</li>
        <li>[April 2024] Interning at Microsoft Research, Redmond this summer.</li>
        <li>[Aug 2023] Our work <i>A Retrieve-and-Read Framework for Knowledge Graph Link Prediction</i> has been accepted to CIKM'23.</li>
        <li>[June 2023] Our work <i>SalsaBot: Towards a Robust and Generalizable Embodied Agent</i> has been accepted to Embodied AI workshop at CVPR 2023.</li>
        <li>[May 2023] My internship work @ Google Brain is accepted to Transformers for Vision (T4V) workshop, CVPR 2023.</li>
        <li>[Feb 2023] Our team Salsabot has qualified to enter the semifinals of <a href="https://www.amazon.science/alexa-prize/simbot-challenge">Alexa Prize Simbot Challenge</a>.</li>
        <li>[Oct 2022] Attending Automated Knowledge Base Construction (AKBC) at London, UK.</li>
        <li>[April 2022] Interning at Google Brain this summer.</li>
        <li>[May 2021] Long paper accepted to ACL 2021 (Oral).</li>
        <li>[March 2021] Interning at Bosch AI Research this summer.</li>
      </ul>
    </section>

    <!-- Research Interests -->
    <section id="research">
      <h2 class="section-heading">Research Interests</h2>
      <p>My research interests lie in LLM agents, multimodal foundation models, and KB reasoning, with a central focus on the role of structure in modern multimodal machine learning. Broadly, I study how leveraging structure, either inherent (<i>e.g.</i>, knowledge graphs) or deliberately synthesized (<i>e.g.</i>, web interaction trajectories), can make multimodal systems more robust, generalizable, and interpretable. My work integrates visual signals, language, and structured knowledge to enhance representation and reasoning (<a href="https://aclanthology.org/2021.acl-long.139.pdf" target="_blank" rel="noopener noreferrer">ACL'21</a>, <a href="https://arxiv.org/pdf/2212.09724.pdf" target="_blank" rel="noopener noreferrer">CIKM'23</a>, <a href="https://arxiv.org/pdf/2401.00608.pdf" target="_blank" rel="noopener noreferrer">CIKM'24</a>) as well as interactive web environments (<a href="https://arxiv.org/pdf/2502.11357" target="_blank" rel="noopener noreferrer">ACL (Findings)'25</a>). I also work on computer-use agents and LLM interpretability, including the use of sparse autoencoders to analyze salient latent structure in dense image representations (<a href="https://openreview.net/pdf?id=oFRbiaib5Q" target="_blank" rel="noopener noreferrer">ICLR'26</a>).</p>
    </section>

    <!-- Publications -->
    <section id="publications">
      <h2 class="section-heading">Publications</h2>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/iclr26.png" alt="ICLR 2026 paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Automatic Image-Level Morphological Trait Annotation for Organismal Images</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a><sup>*</sup>, Samuel Stevens<sup>*</sup>, Alyson East, Sydne Record, Yu Su</p>
          <p class="paper-links">
            <a href="https://openreview.net/pdf?id=oFRbiaib5Q" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <strong>ICLR 2026</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/explorer.png" alt="Explorer paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a><sup>*</sup>, Yadong Lu<sup>*</sup>, Corby Rosset, Boyu Gou, Arindam Mitra, Spencer Whitehead, Yu Su, Ahmed Awadallah</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/2502.11357" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="https://osu-nlp-group.github.io/Explorer/" target="_blank" rel="noopener noreferrer">[website]</a>
            <strong>ACL (Findings) 2025</strong><br>
            <a href="/reports/CSE_poster_Mar_2025_embed.pdf" target="_blank" rel="noopener noreferrer">[poster]</a> OSU CSE Graduate Student Research Poster Exhibition 2025
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/bringing_back.png" alt="Camera Trap paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Reviving the Context: Camera Trap Species Classification as Link Prediction on Multimodal Knowledge Graphs</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Weidi Luo, Yu Gu, Cheng-Hao Tu, Hong-You Chen, Tanya Berger-Wolf, Charles Stewart, Song Gao, Wei-Lun Chao, Yu Su</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/2401.00608.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="https://github.com/OSU-NLP-Group/COSMO/" target="_blank" rel="noopener noreferrer">[code]</a>
            <strong>CIKM 24</strong> (Oral)<br>
            <a href="/reports/CSE_poster_camera_trap.pdf" target="_blank" rel="noopener noreferrer">[poster]</a> Honourable Mention, OSU CSE Graduate Student Research Poster Exhibition 2024<br>
            <a href="/reports/Camera_trap_KG_CV4Animals_workshop.pdf" target="_blank" rel="noopener noreferrer">[short version]</a> CV4Animals workshop, CVPR 24 (Oral)
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/kg_r3.png" alt="KG-R3 paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>A Retrieve-and-Read Framework for Knowledge Graph Link Prediction</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Boshi Wang, Hugo Latapie, Jayanth Srinivasa, Yu Su</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/2212.09724.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="https://github.com/OSU-NLP-Group/KG-R3/" target="_blank" rel="noopener noreferrer">[code]</a>
            <a href="https://link.growkudos.com/1bsgddtkjcw" target="_blank" rel="noopener noreferrer">[blog]</a>
            <strong>CIKM 23</strong> (Oral)
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/diversifying_tokenization.png" alt="Diversifying Tokenization paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Diversifying Joint Vision-Language Tokenization Learning</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, AJ Piergiovanni, Anelia Angelova</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/2306.03421.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="/reports/T4V_poster.pdf" target="_blank" rel="noopener noreferrer">[poster]</a>
            <a href="https://research.google/pubs/diversifying-joint-vision-language-tokenization-learning/" target="_blank" rel="noopener noreferrer">[website]</a>
            <strong>Transformers for Vision workshop, CVPR 2023</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/finetune.png" alt="Fine-Tuning paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Fine-Tuning is Fine, if Calibrated</strong></p>
          <p class="paper-authors">Zheda Mai<sup>*</sup>, Arpita Chowdhury<sup>*</sup>, Ping Zhang<sup>*</sup>, Cheng-Hao Tu, Hong-You Chen, <a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/2409.16223" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <strong>NeurIPS 2024</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/holistic_transfer.png" alt="Holistic Transfer paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data</strong></p>
          <p class="paper-authors">Cheng-Hao Tu, Hong-You Chen, Jike Zhong, Zheda Mai, <a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/2311.01420.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <strong>NeurIPS 2023</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/kbqa_survey.png" alt="KBQA Survey paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Knowledge Base Question Answering: A Semantic Parsing Perspective</strong></p>
          <p class="paper-authors">Yu Gu, <a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Gong Cheng, Yu Su</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/2209.04994.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <strong>AKBC 2022</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/systematic_investigation.png" alt="Systematic Investigation paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>A Systematic Investigation of KB-Text Embedding Alignment at Scale</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Yu Gu, Wenhu Chen, Mehdi Bahrami, Lei Liu, Wei-Peng Chen and Yu Su</p>
          <p class="paper-links">
            <a href="https://aclanthology.org/2021.acl-long.139.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="https://github.com/dki-lab/joint-kb-text-embedding" target="_blank" rel="noopener noreferrer">[code]</a>
            <a href="https://github.com/dki-lab/joint-kb-text-embedding/blob/main/acl_oral_slides.pdf" target="_blank" rel="noopener noreferrer">[slides]</a>
            <strong>ACL 2021</strong> (Oral)<br>
            <a href="/reports/systematic_investigation_poster.pdf">[poster]</a> Also presented at AKBC 22.
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/structure_nmn.png" alt="Structure NMN paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Structure Learning for Neural Module Networks</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Jie Fu, Sarath Chandar, Christopher J Pal</p>
          <p class="paper-links">
            <a href="https://www.aclweb.org/anthology/D19-6401.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="https://github.com/vardaan123/LNMN" target="_blank" rel="noopener noreferrer">[code]</a>
            <a href="/reports/LANTERN_slides.pdf" target="_blank" rel="noopener noreferrer">[slides]</a>
            <strong>LANTERN workshop, EMNLP 2019</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/csqa.png" alt="CSQA paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Complex Sequential Question Answering: Towards Learning to Converse Over Linked Question Answer Pairs with a Knowledge Graph</strong></p>
          <p class="paper-authors">Amrita Saha<sup>*</sup>, <a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a><sup>*</sup>, Mitesh M. Khapra, Karthik Sankaranarayanan, Sarath Chandar</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/1801.10314.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="https://github.com/amritasaha1812/CSQA_Code" target="_blank" rel="noopener noreferrer">[code]</a>
            <a href="https://amritasaha1812.github.io/CSQA/" target="_blank" rel="noopener noreferrer">[website]</a>
            <a href="/reports/CSQA_AAAI.pdf" target="_blank" rel="noopener noreferrer">[slides]</a>
            <strong>AAAI 2018</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/joint_corr_seq.png" alt="Joint Correlated Sequence paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Joint Learning of Correlated Sequence Labeling Tasks Using Bidirectional Recurrent Neural Networks</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja<sup>*</sup></a>, Anirban Laha<sup>*</sup>, Shachar Mirkin, Vikas Raykar, Lili Kotlerman, Guy Lev</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/1703.04650.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <a href="https://github.com/vardaan123/Corr-seq-labeling" target="_blank" rel="noopener noreferrer">[code]</a>
            <strong>Interspeech 2017</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/embc.png" alt="EMBC paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Learning a Probabilistic Boolean Network Model from Biological Pathways and Time-series Expression Data</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Ritwik Kumar Layek, Pabitra Mitra</p>
          <p class="paper-links">
            <a href="http://ieeexplore.ieee.org/abstract/document/7590987/" target="_blank" rel="noopener noreferrer">[paper]</a>
            <strong>EMBC 16</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/salsabot.png" alt="SalsaBot paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>SalsaBot: Towards a Robust and Generalizable Embodied Agent</strong></p>
          <p class="paper-authors">Chan Hee Song, Jiaman Wu, Ju-Seung Byeon, Zexin Xu, <a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Goonmeet Bajaj, Samuel Stevens, Ziru Chen, Yu Su</p>
          <p class="paper-links">
            <a href="https://embodied-ai.org/papers/2023/10.pdf" target="_blank" rel="noopener noreferrer">[short version]</a>
            <strong>Embodied AI Workshop at CVPR 2023</strong><br>
            <a href="https://assets.amazon.science/ea/b7/0895f4e0468680903efcfd67e795/salsabot-report-1.pdf" target="_blank" rel="noopener noreferrer">[long version]</a>
            <strong>Alexa Prize SimBot Challenge Proceedings 2023</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/vqa_cvpr19.png" alt="VQA CVPR19 paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Learning Sparse Mixture of Experts for Visual Question Answering</strong></p>
          <p class="paper-authors"><a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Jie Fu, Christopher J Pal</p>
          <p class="paper-links">
            <a href="https://arxiv.org/pdf/1909.09192.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <strong>Visual Question Answering and Dialog Workshop, CVPR 2019</strong>
          </p>
        </div>
      </div>

      <div class="paper">
        <div class="paper-thumb">
          <img src="images/vldb.png" alt="VLDB paper thumbnail" width="130" height="78">
        </div>
        <div class="paper-body">
          <p class="paper-title"><strong>Tooling framework for instantiating natural language querying system</strong></p>
          <p class="paper-authors">Manasa Jammi, Jaydeep Sen, Ashish Mittal, Sagar Verma, <a href="https://vardaanpahuja.github.io/">Vardaan Pahuja</a>, Rema Ananthanarayanan, Pranay Lohia, Hima Karanam, Diptikalyan Saha, Karthik Sankaranarayanan</p>
          <p class="paper-links">
            <a href="http://www.vldb.org/pvldb/vol11/p2014-jammi.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
            <strong>VLDB Endowment 2018</strong>
          </p>
        </div>
      </div>

    </section>

    <!-- Service / Reviewing -->
    <section id="service">
      <h2 class="section-heading">Service</h2>
      <ul>
        <li><strong>Area Chair</strong>: ARR/EMNLP'25</li>
        <li><strong>Program Committee</strong>: NeurIPS'25, AAAI'25, ICCV'25, ACL'25, NAACL'25, CVPR'25, WACV'25, COLM'24, CVPR'24, EMNLP'23, ACL'23, NAACL'22, Transactions on Big Data'24</li>
        <li><strong>Workshops</strong>: Workshop on Computer-use Agents (ICML'25), CV4Animals (CVPR'24), Knowledge Augmented Methods for NLP (AAAI'23), Structured and Unstructured Knowledge Integration (NAACL'22)</li>
        <li><strong>Secondary Reviewer</strong>: BigData-IT'22, EMNLP'21; SIGKDD'21; ACL'21; SIGKDD'20</li>
      </ul>
    </section>

    <!-- Awards -->
    <section id="awards">
      <h2 class="section-heading">Awards</h2>
      <div class="award-row">
        <span class="award-name"><strong>Honorable Mention Award for Poster</strong>, OSU CSE Graduate Student Research Poster Exhibition</span>
        <span class="award-year">2024</span>
      </div>
      <div class="award-row">
        <span class="award-name"><strong>Institute Silver Medal</strong>, IIT Kharagpur – Best academic performance at graduation</span>
        <span class="award-year">2016</span>
      </div>
      <div class="award-row">
        <span class="award-name"><strong>Prof. J.C. Ghosh Memorial Prize</strong>, IIT Kharagpur – Best academic performance (VI semester)</span>
        <span class="award-year">2015</span>
      </div>
      <div class="award-row">
        <span class="award-name"><strong>International Symposium (Microwave and Comm.) 1981 Prize</strong>, IIT Kharagpur – Best academic performance (VI semester)</span>
        <span class="award-year">2015</span>
      </div>
      <div class="award-row">
        <span class="award-name"><strong>Class of 1970 Alumni (US) Association Prize</strong>, IIT Kharagpur – Best academic performance in Institute (IV semester)</span>
        <span class="award-year">2014</span>
      </div>
      <div class="award-row">
        <span class="award-name"><strong>IIT Kharagpur Alumni (California Chapter) Award</strong>, IIT Kharagpur – Best academic performance in Institute (IV semester)</span>
        <span class="award-year">2014</span>
      </div>
      <div class="award-row">
        <span class="award-name"><strong>National Talent Search Examination (NTSE)</strong> – Award of scholarship under NTSE</span>
        <span class="award-year">2008</span>
      </div>
    </section>

    <footer>
      <a href="https://www.cs.berkeley.edu/~barron/" target="_blank" rel="noopener noreferrer">Website template borrowed from here</a>
    </footer>

  </div><!-- /.page-wrap -->

</body>

</html>

<html>

</html>


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html xmlns="https://www.w3.org/1999/xhtml" xmlns:fb="https://ogp.me/ns/fb#">

  <head>

    <meta name=viewport content="width=800">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="styles.css">
    <title>Vardaan Pahuja</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta property="og:image" content="/images/profile.png" />
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>

  <body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
      <tr>
        <td>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="67%" valign="middle">
                <p id="namechange" align="center">
                  <span id="a"><name><b>Vardaan Pahuja</b></name></span>
                </p>
                <p>I am a Ph.D. student in CSE at The Ohio State University. I am fortunate to be advised by Prof. Yu Su. I graduated with M.Sc. (thesis track) in Computer Science from Université de Montréal (affiliated with MILA). Prior to this, I was working as Software Engineer in IBM India Research Lab., Bangalore. I graduated with Bachelor of Technology (Hons.) from IIT Kharagpur, India.
                </p>
                <p align=center>
                  <a href="mailto:vardaanpahuja AT gmail.com">Email</a> &nbsp/&nbsp
                  <a href="/reports/CV_VardaanPahuja.pdf">CV</a> &nbsp/&nbsp
                  <!-- <a href="https://github.com/chanhee-luke" target="_blank" rel="noopener noreferrer">Github</a> &nbsp/&nbsp -->
                  <a href="https://twitter.com/vardaanpahuja" target="_blank" rel="noopener noreferrer">Twitter</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/vardaanpahuja/" target="_blank" rel="noopener noreferrer"> LinkedIn </a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=0O6NKfIAAAAJ&hl=en" target="_blank" rel="noopener noreferrer"> Google Scholar </a>
                </p>
              </td>
              <td width="33%">
                <img src="images/profile.png">
              </td>
            </tr>
          </table>

        <!--  News -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody><tr>
                <td width="100%" valign="middle">
                  <heading>News</heading>
                  <p>
                      <ul>
                      <li> [May 2025] My internship work Explorer is accepted to ACL (Findings) 2025.
                      <li> [Feb 2025] The preprint for my internship project at Microsoft Research is now available on arXiv <a href="https://arxiv.org/pdf/2502.11357">[Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents]</a>.</li>  
			        <li> [July 2024] Our work <i>Reviving the Context: Camera Trap Species Classification as Link Prediction on Multimodal Knowledge Graphs</i> has been accepted to CIKM'24.</li>
                          <li> [April 2024] Interning at Microsoft Research, Redmond this summer.</li> 
	                        <li> [Aug 2023] Our work <i>A Retrieve-and-Read Framework for Knowledge Graph Link Prediction</i> has been accepted to CIKM'23.
													<li> [June 2023] Our work <i>SalsaBot: Towards a Robust and Generalizable Embodied Agent</i> has been accepted to Embodied AI workshop at CVPR 2023.
													<li> [May 2023] My internship work @ Google Brain is accepted to Transformers for Vison (T4V) workshop, CVPR 2023 <a href="https://arxiv.org/pdf/2306.03421.pdf"> [Diversifying Joint Vision-Language Tokenization Learning]</a>. 
													<li> [Feb 2023] Our team Salsabot has qualified to enter the semifinals of <a href="https://www.amazon.science/alexa-prize/simbot-challenge">Alexa Prize Simbot Challenge</a>.
													<li> [Oct 2022] Attending Automated Knowledge Base Construction (AKBC) at London, UK.</li>
													<li> [April 2022] Interning at Google Brain this summer.</li>
													<li> [May 2021] Long paper accepted to ACL 2021 (Oral).</li>
													<li> [March 2021] Interning at Bosch AI Research this summer.</li>
                        </ul>
                      </p>
                </td>
            </tr></tbody>
        </table>


          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Research Interests</heading>
                <p>
                  <!-- Multimodal Foundation Models, Knowledge Graph Reasoning, Graph Representation Learning, Natural Language Processing -->
                  My research interests lie at the intersection of multimodal foundation models, knowledge base reasoning, and natural language processing. My work primarily focuses on integrating multiple modalities to enhance knowledge representation and reasoning, leveraging visual data (web screenshots), natural language, and interfacing with real-world environments (such as web). Currently, I am working on advancing foundation models for web agents, with a particular emphasis on leveraging synthetic data to train end-to-end generalist GUI agents.
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/explorer.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Explorer: Scaling Exploration-driven Web Trajectory Synthesis for Multimodal Web Agents</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Yadong Lu, Corby Rosset, Boyu Gou, Arindam Mitra, Spencer Whitehead, Yu Su, Ahmed Awadallah<br>
                  <a href="https://arxiv.org/pdf/2502.11357" target="_blank" rel="noopener noreferrer">[pdf] </a><a href="https://osu-nlp-group.github.io/Explorer/" target="_blank" rel="noopener noreferrer">[website] </a><b>ACL (Findings) 2025</b><br>
                  <a href="/reports/CSE_poster_Mar_2025_embed.pdf" target="_blank" rel="noopener noreferrer">[poster]</a> OSU CSE Graduate Student Research Poster Exhibition 2025<br>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/bringing_back.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Reviving the Context: Camera Trap Species Classification as Link Prediction on Multimodal Knowledge Graphs</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Weidi Luo, Yu Gu, Cheng-Hao Tu, Hong-You Chen, Tanya Berger-Wolf, Charles Stewart, Song Gao, Wei-Lun Chao, Yu Su<br>
                  <a href="https://arxiv.org/pdf/2401.00608.pdf" target="_blank" rel="noopener noreferrer">[pdf] </a><a href="https://github.com/OSU-NLP-Group/COSMO/" target="_blank" rel="noopener noreferrer">[code] </a><b>CIKM 24</b> (Oral)<br>
                  <a href="/reports/CSE_poster_camera_trap.pdf" target="_blank" rel="noopener noreferrer">[poster]</a> Honourable Mention, OSU CSE Graduate Student Research Poster Exhibition 2024<br>
                  <a href="/reports/Camera_trap_KG_CV4Animals_workshop.pdf" target="_blank" rel="noopener noreferrer">[short version]</a> CV4Animals workshop, CVPR 24 (Oral)
                  <br>
                </p>
              </td>
            </tr>
          </table>
    			
    			<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/kg_r3.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>A Retrieve-and-Read Framework for Knowledge Graph Link Prediction</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Boshi Wang, Hugo Latapie, Jayanth Srinivasa, Yu Su
                  <br>
                  <a href="https://arxiv.org/pdf/2212.09724.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
                  <a href="https://github.com/OSU-NLP-Group/KG-R3/" target="_blank" rel="noopener noreferrer">[code]</a>
                  <a href="https://link.growkudos.com/1bsgddtkjcw" target="_blank" rel="noopener noreferrer">[blog]</a> <b>CIKM 23 </b>(Oral)
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/diversifying_tokenization.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Diversifying Joint Vision-Language Tokenization Learning</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, AJ Piergiovanni, Anelia Angelova
                  <br>
                  <a href="https://arxiv.org/pdf/2306.03421.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
                  <a href="/reports/T4V_poster.pdf" target="_blank" rel="noopener noreferrer">[poster]</a> <a href="https://research.google/pubs/diversifying-joint-vision-language-tokenization-learning/"target="_blank" rel="noopener noreferrer">[website]</a> <b>Transformers for Vision workshop, CVPR 2023</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>
          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/finetune.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Fine-Tuning is Fine, if Calibrated</strong></anytitle>
                  </a>
                  <br>
                  Zheda Mai<sup>*</sup>, Arpita Chowdhury<sup>*</sup>, Ping Zhang<sup>*</sup>, Cheng-Hao Tu, Hong-You Chen, <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao
                  <br>
                  <a href="https://arxiv.org/pdf/2409.16223" target="_blank" rel="noopener noreferrer">[pdf]</a> <b>NeurIPS 2024</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/holistic_transfer.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Holistic Transfer: Towards Non-Disruptive Fine-Tuning with Partial Target Data</strong></anytitle>
                  </a>
                  <br>
                  Cheng-Hao Tu, Hong-You Chen, Jike Zhong, Zheda Mai, <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Tanya Berger-Wolf, Song Gao, Charles Stewart, Yu Su, Wei-Lun Chao
                  <br>
                  <a href="https://arxiv.org/pdf/2311.01420.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a> <b>NeurIPS 2023</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/kbqa_survey.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Knowledge Base Question Answering: A Semantic Parsing Perspective</strong></anytitle>
                  </a>
                  <br>
                  Yu Gu, <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Gong Cheng, Yu Su
                  <br>
                  <a href="https://arxiv.org/pdf/2209.04994.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a> <b>AKBC 2022</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/systematic_investigation.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>A Systematic Investigation of KB-Text Embedding Alignment at Scale</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Yu Gu, Wenhu Chen, Mehdi Bahrami, Lei Liu, Wei-Peng Chen and Yu Su
                  <br>
                  <a href="https://aclanthology.org/2021.acl-long.139.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
                  <a href="https://github.com/dki-lab/joint-kb-text-embedding" target="_blank" rel="noopener noreferrer">[code]</a>
                  <a href="https://github.com/dki-lab/joint-kb-text-embedding/blob/main/acl_oral_slides.pdf" target="_blank" rel="noopener noreferrer">[slides]</a> <b>ACL 2021</b> (Oral)<br>
                  <a href='/reports/systematic_investigation_poster.pdf'>[poster]</a> Also presented at AKBC 22.
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/structure_nmn.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Structure Learning for Neural Module Networks</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'><a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Jie Fu, Sarath Chandar, Christopher J Pal
                  <br>
                  <a href="https://www.aclweb.org/anthology/D19-6401.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
                  <a href="https://github.com/vardaan123/LNMN" target="_blank" rel="noopener noreferrer">[code]</a>
                  <a href="/reports/LANTERN_slides.pdf" target="_blank" rel="noopener noreferrer">[slides]</a> <b>LANTERN workshop, EMNLP 2019</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/csqa.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Complex Sequential Question Answering: Towards Learning to Converse Over Linked Question Answer Pairs with a Knowledge Graph</strong></anytitle>
                  </a>
                  <br>
                  Amrita Saha<sup>*</sup>, <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a><sup>*</sup>, Mitesh M. Khapra, Karthik Sankaranarayanan, Sarath Chandar
                  <br>
                  <a href="https://arxiv.org/pdf/1801.10314.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
                  <a href="https://github.com/amritasaha1812/CSQA_Code" target="_blank" rel="noopener noreferrer">[code]</a>
                  <a href="https://amritasaha1812.github.io/CSQA/" target="_blank" rel="noopener noreferrer">[website]</a>
                  <a href="/reports/CSQA_AAAI.pdf" target="_blank" rel="noopener noreferrer">[slides]</a> <b>AAAI 2018</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/joint_corr_seq.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Joint Learning of Correlated Sequence Labeling Tasks Using Bidirectional Recurrent Neural Networks</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja<sup>*</sup></a>, Anirban Laha<sup>*</sup>, Shachar Mirkin, Vikas Raykar, Lili Kotlerman, Guy Lev
                  <br>
                  <a href="https://arxiv.org/pdf/1703.04650.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a>
                  <a href="https://github.com/vardaan123/Corr-seq-labeling" target="_blank" rel="noopener noreferrer">[code]</a> <b>Interspeech 2017</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/embc.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Learning a Probabilistic Boolean Network Model from Biological Pathways and Time-series Expression Data</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Ritwik Kumar Layek, Pabitra Mitra
                  <br>
                  <a href="http://ieeexplore.ieee.org/abstract/document/7590987/" target="_blank" rel="noopener noreferrer">[paper]</a> <b>EMBC 16</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/salsabot.png" alt="salsabot" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                  <!-- <a href="https://chanh.ee"> -->
                    <anytitle><strong>SalsaBot: Towards a Robust and Generalizable Embodied Agent</strong></anytitle>
                  </a>
                  <br>
                  Chan Hee Song, Jiaman Wu, Ju-Seung Byeon, Zexin Xu, <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Goonmeet Bajaj, Samuel Stevens, Ziru Chen, Yu Su
                  <br>
                  <a href="https://embodied-ai.org/papers/2023/10.pdf" target="_blank" rel="noopener noreferrer">[short version]</a> <b>Embodied AI Workshop at CVPR 2023</b>
                  <br>
                  <a href="https://assets.amazon.science/ea/b7/0895f4e0468680903efcfd67e795/salsabot-report-1.pdf" target="_blank" rel="noopener noreferrer">[long version]</a> <b>Alexa Prize SimBot Challenge Proceedings 2023</b>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/vqa_cvpr19.png" alt="vqa cvpr19" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Learning Sparse Mixture of Experts for Visual Question Answering</strong></anytitle>
                  </a>
                  <br>
                  <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Jie Fu, Christopher J Pal
                  <br>
                  <a href="https://arxiv.org/pdf/1909.09192.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a> <b>Visual Question Answering and Dialog Workshop, CVPR 2019</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
            	<td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/vldb.png" alt="palix" width="160" height="80">
              </td>
              <td width="75%" valign="middle">
                <p>
                    <anytitle><strong>Tooling framework for instantiating natural language querying system</strong></anytitle>
                  </a>
                  <br>
                  Manasa Jammi, Jaydeep Sen, Ashish Mittal, Sagar Verma, <a href='https://vardaan123.github.io/'>Vardaan Pahuja</a>, Rema Ananthanarayanan, Pranay Lohia, Hima Karanam, Diptikalyan Saha, Karthik Sankaranarayanan
                  <br>
                  <a href="http://www.vldb.org/pvldb/vol11/p2014-jammi.pdf" target="_blank" rel="noopener noreferrer">[pdf]</a> <b>VLDB Endowment 2018</b>
                  <br>
                </p>
              </td>
            </tr>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody><tr>
                <td>
                  <br>
                  <p align="right"><font size="2">
                      <br><a href="https://www.cs.berkeley.edu/~barron/" target="_blank" rel="noopener noreferrer">(website template borrowed from here)</a>
                  </td>
                </tr>
              </tbody>
            </table>
            
      </tr>

    </table>

  </body>

</html>
